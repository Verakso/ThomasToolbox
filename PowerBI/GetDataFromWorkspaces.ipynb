{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data From Workspaces\n",
    "\n",
    "In this notebook we, log on to our PowerBI workspaces, and iterate over them and fecth all data on all avalailiable `datasets` and `reports`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we install the needed libraries, but only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the InteractiveBrowserCredential to get the access token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import InteractiveBrowserCredential\n",
    "import requests\n",
    "\n",
    "# Initialize the credential\n",
    "credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Define the scope for Power BI API\n",
    "scope = [\"https://analysis.windows.net/powerbi/api/.default\"]\n",
    "\n",
    "# Get the access token\n",
    "token = credential.get_token(*scope).token\n",
    "\n",
    "print(f\"Token: {token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the obtained token, let's see the list of workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the token to make API requests\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {token}'\n",
    "}\n",
    "\n",
    "# Example: Get workspaces\n",
    "url = 'https://api.powerbi.com/v1.0/myorg/groups'\n",
    "response = requests.get(url, headers=headers)\n",
    "workspaces = response.json()\n",
    "\n",
    "print(f\"Found  {len(workspaces['value'])} availiable workpaces\")\n",
    "\n",
    "for workspace in workspaces['value']:\n",
    "    print(f\"Workspace Name: {workspace['name']}, Workspace ID: {workspace['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define some functions we can use to retrieve the data that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get all workspaces\n",
    "def get_workspaces():\n",
    "    url = 'https://api.powerbi.com/v1.0/myorg/groups'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Function to get reports in a workspace\n",
    "def get_reports(workspace_id):\n",
    "    url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/reports'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Function to get datasets in a workspace\n",
    "def get_datasets(workspace_id):\n",
    "    url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Function to get the last refresh time of a dataset\n",
    "def get_dataset_refresh_history(workspace_id, dataset_id):\n",
    "    url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{dataset_id}/refreshes'\n",
    "    params = {\n",
    "        '$top': \"1\"\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Fetch all workspaces\n",
    "workspaces = get_workspaces()\n",
    "\n",
    "# List to store report information\n",
    "report_list = []\n",
    "\n",
    "# List to store dataset information\n",
    "datasets_list = []\n",
    "\n",
    "# Iterate through workspaces and fetch reports and datasets\n",
    "for workspace in workspaces['value']:\n",
    "    workspace_id = workspace['id']\n",
    "    workspace_type = workspace[\"type\"]\n",
    "    workspace_name = workspace['name']\n",
    "\n",
    "    print(f\"Workspace Name: {workspace_name}\\tWorkspace Type: {workspace_type}\\tWorkspace Id: {workspace_id}\")\n",
    "   \n",
    "    # Fetch reports\n",
    "    reports = get_reports(workspace_id)\n",
    "    for report in reports['value']:\n",
    "        report_name = report['name']\n",
    "        report_id = report['id']\n",
    "        report_type = report[\"reportType\"]\n",
    "        # Not all attributes are avaliable on all reports, so here we use get to be more fault tolerant\n",
    "        report_web_url = report.get(\"webUrl\")\n",
    "        report_dataset_workspace_id = report.get(\"datasetWorkspaceId\")\n",
    "        report_dataset_id = report.get(\"datasetId\")\n",
    "\n",
    "        # print(f\"Report Name: {report['name']}, Report ID: {report['id']}, Workspace ID: {workspace_id}, Owner: {report['createdBy']}, Last Refresh: {report['lastModifiedDateTime']}\")\n",
    "        # Add report information to the list\n",
    "        report_list.append({\n",
    "            \"workspace_name\": workspace_name,\n",
    "            \"workspace_id\": workspace_id,\n",
    "            \"name\": report_name,\n",
    "            \"id\": report_id,\n",
    "            \"report_type\": report_type,\n",
    "            \"web_url\": report_web_url,\n",
    "            \"dataset_workspace_id\": report_dataset_workspace_id,\n",
    "            \"dataset_id\": report_dataset_id\n",
    "        })\n",
    "\n",
    "\n",
    "    # Fetch datasets (semantic models)\n",
    "    datasets = get_datasets(workspace_id)\n",
    "    for dataset in datasets['value']:\n",
    "        dataset_name = dataset['name']\n",
    "        dataset_id = dataset['id']\n",
    "        #refresh_history = get_dataset_refresh_history(workspace_id, dataset_id)\n",
    "        #last_refresh = refresh_history['value'][0]['endTime'] if refresh_history['value'] else 'No refresh history'\n",
    "        # print(f\"Dataset Name: {dataset['name']}, Dataset ID: {dataset['id']}, Workspace ID: {workspace_id}, Last Refresh: {last_refresh}\")\n",
    "        print(f\"Dataset Name: {dataset['name']}, Dataset ID: {dataset['id']}, Workspace ID: {workspace_id}\")\n",
    "         # Add dataset information to the list\n",
    "        datasets_list.append({\n",
    "            \"workspace_name\": workspace_name,\n",
    "            \"workspace_id\": workspace_id,\n",
    "            \"name\": dataset_name,\n",
    "            \"id\": dataset_id\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the data, for easier access in `Excel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas DataFrame for easy handling\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_reports = pd.DataFrame(report_list)\n",
    "df_datasets = pd.DataFrame(datasets_list)\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "directory = './data'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the data as Excel files\n",
    "df_reports.to_excel(f'{directory}/reports.xlsx', index=False)\n",
    "df_datasets.to_excel(f'{directory}/datasets.xlsx', index=False)\n",
    "\n",
    "print(f'Written output to {directory}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
